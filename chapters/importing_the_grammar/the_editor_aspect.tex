\section{The editor aspect}
\label{chap:editor_aspect}

After we have imported all concepts, their contents (properties) and linked them together (child links), it is time to define, what is the visual representation of these concepts.
Without this, we are not able to start using the language inside MPS.
\\

As stated before (section~\ref{chap:about_editor_aspect}), MPS uses a cellular system, that allows placing concept's properties and children into a table-like arrangement.
MPS has a lot of a different types of cells, that we can use:

\begin{itemize}
	\item Cells for storing values of properties -- user can enter text inside, which is validated using the type of the property (think XML tag name).
	
	\item Cells for storing child concepts -- here we can store other parser rule references and build the AST further.
	
	\item Cells that have static fixed content, such as constant keyword -- we will use these to display literal elements.
	
	\item Cells that influence the layout, such as indenting.
\end{itemize}

Our import plugin has to create these cells and ideally project all of concept's elements in there.
\\

A part of this thesis' mission was to explore, whether we can also bring some more value into this import step.
The problem with grammars is, that it serves us no aid when it comes to element layout.
The grammar only defines, what the rule breaks up into and which elements (rule references, literals..) are contained inside of each alternative.
We will look into the problem of creating this missing information, either with users help or using some heuristics.
It is a very hard problem though, since our plugin doesn't really understand the contents of the grammar on some higher level.

\subsection{The interactive approach}

Since the layout information is just missing, we decided to ask the user for it.
First idea on how to tackle this problem, was to interactively prompt the user during the import process.
We would somehow select rules, that we consider important, and give the user several visual options on how we think this rule might be laid out.
The user would pick one and we would use this information to create the editor aspect.
There are some problems with this though, that led the author to rejecting this approach.

\subsubsection{Detecting interesting rules}

Firstly, we would have to be able to tell, which rules might be worth "discussing" with the user.
\\

The first idea for a heuristic indicating these "interesting" rules was based on number of elements contained in rule's alternative.
For simple rules, which there usually is a big number present in the grammar, we would skip them.
For complex rules (let's say 5 elements and more), we would ask the user for help with the layout.
The heuristics isn't bad, it would detect complicated rules, such as cycles, branching commands and so on, so it might be a sufficient, yet simple, solution.
It, however, has some problems --- rules describing a block of statements are usually very simple, example given being the JavaScript one:

\begin{antlr}
	\parserrule{statementList} : \parserrule{statement}* ;
\end{antlr}

This rule would be skipped by our heuristics, since the alternative has only one element, but in most general purpose languages, this is exactly the kind of statement, that we would like to alter, since normally we put each statement on a separate line.
There are dozens of rules, that have this form though (method parameters, operands, ...), and we have no means of recognizing, that this particular one should be a vertical list (meaning its elements should be separated with a new line).
\\

Another heuristics suggestion was detecting pair symbols among alternative's literal elements.
Usually, characters such as braces are a good indicator of some indenting.
We, however, did not implement any of these heuristics, because in the end, we decided to abandon the interactive approach completely, as described below in \ref{chap:interactive_approach_evaluation}.
That is why, we will not go into more detail here.

\subsubsection{Fixing rule layout}

Once we have detected a rule, that might have some interesting layout, we would ask the user to help us with it.
Consider, for example, the first alternative of the \parserrule{element} rule from the XML language:

\begin{antlr}
	\parserrule{element}  :   \literal{<} \lexerrule{Name} \parserrule{attribute}* \literal{>} \parserrule{content}* \literal{</} \lexerrule{Name} \literal{>} ;
\end{antlr}

Let's say, we would prepare few versions of how we think the layout could look like.
We would present these options to the user and let them choose.
We could ask the user, whether attributes should be spread out horizontally or each on a new line.
We could and probably would have to do this for each element, since the plugin has no real understandind of the content.
We would have to ask for identation, line breaks etc. and we would probably not guess right, since there are just too many options.
The user would probably end up finalizing the layout himself.
\\

The other option would be some even more sophisticated, where the user would control the layout through some smart dialog and drag the elements around or position them through some text field.
Again, we are not going into any more detail, as this approach was rejected because of reasons mentioned below.

\subsubsection{Approach evaluation}
\label{chap:interactive_approach_evaluation}

The author of this thesis came to a conclusion, that the results of the interactive approach would be most likely quite suboptimal.
It would be hard to recognize rules, that are in need of a refactoring.
Furthermore, when asking for user's help, we would just duplicate the functionality of MPS's built-in projectional editor.
We would hardly mimic all of its functionality and put a lot of effort into something already existent.
Moreover, our end user is expected to have knowledge of the MPS editor, since he is importing language there.
This means, that he probably knows his way around the projectional editor too.
It wouldn't make sense to force the user to learn working with our own interactive dialog, while in background, this dialog would be just translating the layout back into the terms of the projectional editor.
Implementing such mechanism would also probably be very complicated.

\subsection{The learning approach}
\label{chap:learning_approach}

The second approach is more complex and might yield better results.
We have, however, not implemented it to a stage, that would be presentable, as we met some obstacles.
We would like to describe it anyway, so possible follow-up work might take it into consideration.
\\

\subsubsection{Approach principle}

The learning approach would require user to, together with the grammar file, supply a set of valid source files written in given language.
The plugin would automatically generate an ANTLR parser for this language using the ANTLR library, which provides this functionality.
It would alter the code of the generated parser and add some additional functionality, described below.
Then it would compile it into an executable form.
After that, we would parser the supplied source code and extract information about the layout of the code.
The benefit of this approach is, that the imported language would inherit its code style from the user, as it would learn directly from his code.
The quality of the extracted information would depend on the amount and the quality of the code supplied.
So far, this approach sounds very complicated --- extracting layout information sounds like a difficult problem on its own.
We have, however, found a simple way, how to mine information very efficiently.
\\

When the ANTLR parser is parsing the code, in its first stage, it reads the input and tries to split it into tokens.
In the second stage, it tries to build the AST out of these tokens.
Earlier, we said, that we will change the code of the parser.
We would make sure, that each token would contain additional information --- the number of the line it appeared on.
This is an easily accessible property of the parser.
\\

\noindent
For example, for our \parserrule{element} rule

\begin{antlr}
	\parserrule{element}  :   \literal{<} \lexerrule{Name} \parserrule{attribute}* \literal{>} \parserrule{content}* \literal{</} \lexerrule{Name} \literal{>} ;
\end{antlr}

\noindent
and following source code,

\begin{antlr}
	1   <element>
	2      ... some content ...
	3   </element>
\end{antlr}

\noindent
it would yield something like this:

\begin{antlr}
	<       1
	Name    1
	>       1
	\textcolor{gray}{// Here, tokens of the content would come}
	</      3
	Name    3
	>       3
\end{antlr}

From this, we could clearly derive, that there is a line break between the first closing \textit{greater-than} bracket, the content and then again when the closing tag starts.
Probably, we might also be able to detect indentation, if we would decide to store the column information too, but we haven't explored this possibility.

\subsubsection{Approach evaluation}

We have started implementing a proof of concept of this approach, so that we can see, whether it is a viable solution.
Unfortunately, there were some obstacles, due to which we haven't finished the implementation.
The biggest problem, that we have identified, was parser generation.
We found out, that even a small tweaks in the grammar, that the user might perform in order to improve the resulting MPS language, can break it enough, so that the automatically generated parser is broken.
We talk further about this problem in more detail in chapter \ref{chap:breaking_the_parser}.
\\

Other problems, that we have identified, were connected to the environment, where it might not be always possible, to perform actions such as parser generation, parser compilation or dynamic loading of the parser.
More problems concerned the algorithm itself, where we would need to be able to match language concepts with all tokens that belong to it.
Mapping the parsed ANTLR AST to the MPS one is a complex problem, that is also connected to parsing any given text source code and importing it inside MPS.
This is considered as an advanced functionality, that will probably be a subject to a separate follow-up work.
\\

Because of the overall complexity of this approach and because of reasons stated in \ref{chap:editor_solution}, we have decided to abandon the implementation and only suggest it as a possible follow-up.
We, however, concluded, that this might be a viable solution for detecting code layout.

\subsection{Our solution}
\label{chap:editor_solution}

When the author of this thesis worked on the plugin, he noticed, that the most tiresome and likely error-prone part of working on the editor aspect is incorporating all concept's properties, children and constant fields into the editor.
This means manual creation of all cells, that should appear in the visual representation.
We identified this phase as a time consuming but also quite straightforward, as it does not require any major thought on user's part.
The author has further noticed, that when the plugin would do this heavy lifting, even without layout detection, further adjustments of the editor are very fast, since MPS enables doing this very efficiently.
We noticed, that even the most obvious way of editor generation, such as plain inlining of all of the cells in a single row (shown in figure \ref{fig:editor_adjustment} on top), might be a sufficient solution.
In figure \ref{fig:editor_adjustment}, we can see an editor adjustment of the \concept{Element{\_}1} concept, that can be done in just few clicks, but finalizes the editor to its perfect form.
\\

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{./img/editor_adjustment.png}
	\caption{Projectional editor adjustment of the Element{\_}1 concept}
	\label{fig:editor_adjustment}
\end{figure}

From these reasons, we concluded, that for our cause, it might be sufficient, if the plugin only prepared contents of all editor aspects and the end user would take it from there, reaching optimal results in a very short time.
We have confirmed this assumption by importing the JavaScript language~\cite{javascript} and manually adjusting all editors, that needed it, in a less than hour time.
Further improvements might be a subject for a follow-up work, potentially leveraging the second approach, we have described above in \ref{chap:learning_approach}.

