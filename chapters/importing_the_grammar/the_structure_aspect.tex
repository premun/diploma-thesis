\section{The structure aspect}

After we have mined the structure of the language out of the grammar file, we can finally start working with MPS.
We need to translate our tree structure into the terms of MPS.
That means creating concepts inside the structure aspect and linking them together appropriately.
\\

We will describe several different attempts (sections \ref{chap:straightforward_approach} and \ref{chap:shortcut_approach}) the author has tried out and show some problems these attempts introduced.
We consider it a better approach than just simple description of the final solution, because it might prevent others from falling into similar pitfalls such as we discovered ourselves.


\subsection{Concept types}

Before we start describing how we decided to import our tree structure into MPS, we should remind in more detail which means of expression are available to us.
As stated before, concepts are building blocks of all MPS languages and they can be treated similarly as Java classes.
They can:

\begin{itemize}
	\item extend a parent concept
	\item inherit any number of interfaces (interface concepts)
	\item have properties (similar to class fields) with a given data type --- either a primitive type such as string or integer, or a constraint data type --- a string whose value is restricted by a regular expression
	\item have children concepts (defined as a concept or an interface concept)
	\item hold references to other nodes (e.g. function call statement would know reference to the function definition)
\end{itemize}

\subsection{Common ground}

Some of the import steps are common for both approaches (\ref{chap:straightforward_approach}, \ref{chap:shortcut_approach}).
Firstly, we have noticed, that whenever there is a string literal inside a parser rule's alternative (think of the \textbf{for} keyword from a Java loop), it will appear only in that rule's projectional editor.
There is no need for it to have any function as it is set in stone as an unchangeable part of that alternative's appearance.
It might serve its purpose when describing or naming this alternative inside an auto-complete menu, but we will get to that part later.
\\

Secondly, we can take the flattened lexer rules, that contain the regular expression, we have built by gluing its parts together in the parsing stage. 
For each one of these, we create a constraint data type concept, which is exactly what we need. 
We will be able to later create properties of concepts and set their data type as this constraint data type concept, effectively restricting their value using given regular expression.
\\

To illustrate what a concept for a sample alternative looks like, consider the element concept that represents the full XML tag with content:

\begin{antlr}
	\parserrule{element}      :   \literal{<} \lexerrule{Name} \parserrule{attribute}* \literal{>} \parserrule{content}* \literal{</} \lexerrule{Name} \literal{>}
             \textcolor{gray}{|   \ap<\ap Name attribute* \ap/>\ap}
             \textcolor{gray}{;}
\end{antlr}

Because we are creating a new concept for each alternative of the rule, we will be numbering them correspondingly.
The concept, that will represent the first alternative of the \parserrule{element} rule, will therefore be named \concept{Element{\_}1}
(we will mark concepts \concept{purple} and interfaces \interface{pink}).

\begin{itemize}
	\item Since there are two references to the \lexerrule{Name} lexer rule inside the first alternative of the \parserrule{element} rule, the \concept{Element{\_}1} concept will contain two properties, whose value will be restricted using the regular expression representing the \lexerrule{Name} rule. 
	We can achieve this using the \textit{Constraint data type concept}, which we create for each lexer rule.

	\item Literals are skipped (as explained above using the \textbf{for} keyword). 

	\item Parser rules references (\parserrule{attribute} and \parserrule{content}) will be explained further down the road as they are the part where approaches differ.
\end{itemize}

Result of this first step can be seen in figure \ref{fig:element_concept_common}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{./img/element_concept_common.png}
	\caption{Resulting \textit{Element{\_}1} concept}
	\label{fig:element_concept_common}
\end{figure}

Next, we are going to describe two different approaches --- the straightforward approach (section \ref{chap:straightforward_approach}) and the shortcut approach (section \ref{chap:shortcut_approach}).
The difference between these two lies in the way we create children fields for parser rules and in the way we are going to link them together using interface concepts.
Final solution will be described in section \ref{chap:structure_solution}.

\pagebreak

\input{chapters/importing_the_grammar/the_straightforward_approach}

\pagebreak

\input{chapters/importing_the_grammar/the_shortcut_approach}

\pagebreak

\subsection{Our solution}
\label{chap:structure_solution}

In the end, we have decided to go with the shortcut approach using smart interfaces. 
As we have stated above, it has several advantages, concerning the solution complexity, compared to the smart auto-completion.
It only has one disadvantage regarding the cardinality restriction, described in \ref{chap:cardinality_restriction}.
We have analyzed several ANTLR grammars (such as the JavaScript\footnote{https://github.com/antlr/grammars-v4/blob/master/ecmascript/ECMAScript.g4} one) and we haven't found a single intermediate rule, that would be suffering from this restriction.
It is quite understandable, if you think about how grammars are written.
Usually, you create the basic structure (i.e. different kinds of statements) in the simplest way possible, and put the quantitative operator rather to an alternative that is referencing the structure.
\\

Based on these observations and some grammar analysis, we concluded that advantages prevail and used the last mentioned approach.

\subsection{The structure aspect and other ANTLRv4 features}

The ANTLR grammar notation offers more features than just rule definition. 
We haven't mentioned these earlier because we were focusing solely on the structure of the language. 
We will mention some features and explain why we have ignored them and why they doesn't matter to us. 
We will not spend a lot of time on describing details of these as they are well documented in the official ANTLR reference~\cite{ANTLR4reference}.

\subsubsection{Modes}

For example, just like any other parser/lexer, ANTLR gives us the possibility to switch the parsing context. 
We are able to create various user specified modes and then enter these modes when certain rules/tokens are encountered. 
For each mode we can define different set of rules/tokens that can only be applied when the parser is in that particular mode. 
The syntax is following:

\begin{antlr}
	\textcolor{gray}{// Enter mode when tag opened}
	\lexerrule{OPEN}        :   \literal{<}       -> pushMode(INSIDE) ;
	
	mode INSIDE;
	\textcolor{gray}{// Special rules bound to specific mode}
	\lexerrule{S}           :   \regex{[ {\textbackslash}t{\textbackslash}r{\textbackslash}n]} -> skip ;
	
	\textcolor{gray}{// Leave the mode when tag closed}
	\lexerrule{CLOSE}       :   \literal{>}       -> popMode ;
	\lexerrule{SLASH{\_}CLOSE} :   \literal{/>}      -> popMode ;
\end{antlr}

We didn't pay any extra attention to modes while dealing with the structural aspect, because they don't really influence contents of individual concepts.
It is even possible to define concepts that control mode switching and then not including them inside any parser rule.
They still get recognized by the lexer and mode is changed.
\\

The reason that this goes beyond our interest here is partially caused by the fact, that modes are used on runtime, when we are parsing actual code, whereas language structure is more of a static matter.
The only time we care about modes is when generating the TextGen aspect, and we will get back to it later in chapter \ref{chap:textgen}.

\subsubsection{Actions, attributes and semantic predicates}

Actions allow us to append code to rules and this code is then executed every time the parser applies this rule.
The code is written in the target language that you are creating the parser for.
It is then copied as a string and inserted into the method that is bound to parsing this rule.
Again, this is of a little interest to us.
Usually, this is used when creating some specific parsers for some particular scenario.
We, however, are expecting to parse general purpose languages that contain actions just rarely.
And even when they did, we cannot be sure what language will it be in and how to use it.
\\

Attributes allow us to extend some basic predefined set of properties of each rule.
We can store some arbitrary information there and later access it for example inside actions using special syntax.
From exactly the same reasons as with actions, attributes are of no interest to us.
\\

Semantic predicates tell the parser on runtime, which rules can be applied depending on user specified constraints.
Again, this is a runtime matter and we will ignore it.
